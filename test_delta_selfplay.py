"""
æµ‹è¯• Delta-Uniform Self-Play å®ç°
è¿è¡Œæ­¤è„šæœ¬éªŒè¯æ‰€æœ‰ç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import numpy as np
from gymnasium import spaces


def test_baseline_policies():
    """æµ‹è¯•åŸºå‡†ç­–ç•¥"""
    print("=" * 70)
    print("æµ‹è¯• 1: åŸºå‡†ç­–ç•¥ (RandomPlayerPolicy, MinMaxPlayerPolicy)")
    print("=" * 70)

    from gym_env.policies import RandomPlayerPolicy, MinMaxPlayerPolicy

    # åˆ›å»ºç©ºé—´
    obs_space = spaces.Box(low=-1, high=1, shape=(9,), dtype=np.float32)
    act_space = spaces.Discrete(9)

    # æµ‹è¯• RandomPlayerPolicy
    print("\n[1.1] RandomPlayerPolicy")
    random_policy = RandomPlayerPolicy(obs_space, act_space)

    test_board = np.array([1, 0, -1, 0, 1, 0, 0, 0, -1], dtype=np.float32)
    print(f"Board:\n{test_board.reshape(3, 3)}")

    for i in range(3):
        action, _ = random_policy.predict(test_board)
        print(f"  Trial {i+1}: action={action}")

    # æµ‹è¯• MinMaxPlayerPolicy
    print("\n[1.2] MinMaxPlayerPolicy")
    minmax_policy = MinMaxPlayerPolicy(obs_space, act_space)

    # æµ‹è¯•åœºæ™¯1ï¼šç®€å•è·èƒœæœºä¼š
    board1 = np.array([1, 1, 0, 0, 0, 0, 0, 0, 0], dtype=np.float32)
    print(f"\nBoard (should choose 2 to win):")
    print(board1.reshape(3, 3))
    action, _ = minmax_policy.predict(board1)
    print(f"Action: {action} (expected: 2)")

    # æµ‹è¯•åœºæ™¯2ï¼šç©ºæ£‹ç›˜
    board2 = np.zeros(9, dtype=np.float32)
    print(f"\nBoard (empty, should choose center=4):")
    print(board2.reshape(3, 3))
    action, _ = minmax_policy.predict(board2)
    print(f"Action: {action} (expected: 4)")

    print("\nâœ“ åŸºå‡†ç­–ç•¥æµ‹è¯•é€šè¿‡")
    return True


def test_delta_selfplay_env():
    """æµ‹è¯• Delta-Uniform Self-Play ç¯å¢ƒ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: Delta-Uniform Self-Play ç¯å¢ƒ")
    print("=" * 70)

    import gymnasium as gym
    from gym_env.tictactoe_delta_selfplay import TicTacToeDeltaSelfPlayEnv
    from gym_env.policies import RandomPlayerPolicy, MinMaxPlayerPolicy

    # åˆ›å»ºåŸºå‡†ç­–ç•¥
    obs_space = spaces.Box(low=-1, high=1, shape=(9,), dtype=np.float32)
    act_space = spaces.Discrete(9)

    baseline_pool = [
        RandomPlayerPolicy(obs_space, act_space),
        MinMaxPlayerPolicy(obs_space, act_space)
    ]

    # åˆ›å»ºç¯å¢ƒ
    print("\n[2.1] åˆ›å»ºç¯å¢ƒ")
    env = TicTacToeDeltaSelfPlayEnv(
        baseline_pool=baseline_pool,
        learned_pool=None,
        play_as_o_prob=0.5
    )
    print(f"  è§‚å¯Ÿç©ºé—´: {env.observation_space}")
    print(f"  åŠ¨ä½œç©ºé—´: {env.action_space}")
    print(f"  åŸºå‡†æ± å¤§å°: {len(env.baseline_pool)}")

    # æµ‹è¯•å…ˆæ‰‹
    print("\n[2.2] æµ‹è¯•æ¸¸æˆæµç¨‹ (å…ˆæ‰‹ X)")
    obs, info = env.reset(seed=42)
    print(f"  Playing as: {'O (åæ‰‹)' if env.play_as_o else 'X (å…ˆæ‰‹)'}")
    print(f"  Initial observation:\n{obs.reshape(3, 3)}")

    for step in range(3):
        legal_actions = np.where(obs == 0)[0]
        if len(legal_actions) == 0:
            break
        action = np.random.choice(legal_actions)

        obs, reward, terminated, truncated, info = env.step(action)
        print(f"\n  Step {step + 1}: action={action}, reward={reward}")
        print(f"  Observation:\n{obs.reshape(3, 3)}")

        if terminated:
            print(f"  Game ended: {info}")
            break

    env.close()
    print("\nâœ“ Delta-Uniform Self-Play ç¯å¢ƒæµ‹è¯•é€šè¿‡")
    return True


def test_environment_registration():
    """æµ‹è¯•ç¯å¢ƒæ³¨å†Œ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: ç¯å¢ƒæ³¨å†Œ")
    print("=" * 70)

    import gymnasium as gym

    print("\n[3.1] æ£€æŸ¥ TicTacToe-v0")
    env1 = gym.make('TicTacToe-v0')
    print(f"  âœ“ TicTacToe-v0 æ³¨å†ŒæˆåŠŸ: {type(env1)}")
    env1.close()

    print("\n[3.2] æ£€æŸ¥ TicTacToe-SelfPlay-v0")
    env2 = gym.make('TicTacToe-SelfPlay-v0')
    print(f"  âœ“ TicTacToe-SelfPlay-v0 æ³¨å†ŒæˆåŠŸ: {type(env2)}")
    env2.close()

    print("\n[3.3] æ£€æŸ¥ TicTacToe-DeltaSelfPlay-v0")
    env3 = gym.make('TicTacToe-DeltaSelfPlay-v0')
    print(f"  âœ“ TicTacToe-DeltaSelfPlay-v0 æ³¨å†ŒæˆåŠŸ: {type(env3)}")
    env3.close()

    print("\nâœ“ ç¯å¢ƒæ³¨å†Œæµ‹è¯•é€šè¿‡")
    return True


def test_training_imports():
    """æµ‹è¯•è®­ç»ƒè„šæœ¬çš„å¯¼å…¥"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 4: è®­ç»ƒè„šæœ¬å¯¼å…¥")
    print("=" * 70)

    try:
        print("\n[4.1] å¯¼å…¥å¿…éœ€æ¨¡å—")
        from stable_baselines3 import DQN
        from stable_baselines3.common.vec_env import DummyVecEnv
        from stable_baselines3.common.monitor import Monitor
        from collections import deque
        print("  âœ“ stable-baselines3 å¯¼å…¥æˆåŠŸ")

        print("\n[4.2] å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—")
        from gym_env.tictactoe_delta_selfplay import TicTacToeDeltaSelfPlayEnv
        from gym_env.policies import RandomPlayerPolicy, MinMaxPlayerPolicy
        print("  âœ“ è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æˆåŠŸ")

        print("\nâœ“ è®­ç»ƒè„šæœ¬å¯¼å…¥æµ‹è¯•é€šè¿‡")
        return True

    except ImportError as e:
        print(f"\nâœ— å¯¼å…¥å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print()
    print("=" * 70)
    print("Delta-Uniform Self-Play å®ç°æµ‹è¯•å¥—ä»¶")
    print("=" * 70)

    results = []

    try:
        results.append(("åŸºå‡†ç­–ç•¥", test_baseline_policies()))
    except Exception as e:
        print(f"\nâœ— åŸºå‡†ç­–ç•¥æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("åŸºå‡†ç­–ç•¥", False))

    try:
        results.append(("Delta-Uniform ç¯å¢ƒ", test_delta_selfplay_env()))
    except Exception as e:
        print(f"\nâœ— Delta-Uniform ç¯å¢ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("Delta-Uniform ç¯å¢ƒ", False))

    try:
        results.append(("ç¯å¢ƒæ³¨å†Œ", test_environment_registration()))
    except Exception as e:
        print(f"\nâœ— ç¯å¢ƒæ³¨å†Œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("ç¯å¢ƒæ³¨å†Œ", False))

    try:
        results.append(("è®­ç»ƒè„šæœ¬å¯¼å…¥", test_training_imports()))
    except Exception as e:
        print(f"\nâœ— è®­ç»ƒè„šæœ¬å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        results.append(("è®­ç»ƒè„šæœ¬å¯¼å…¥", False))

    # æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)

    for name, passed in results:
        status = "âœ“ é€šè¿‡" if passed else "âœ— å¤±è´¥"
        print(f"{name:20s}: {status}")

    all_passed = all(r[1] for r in results)
    print()
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚")
        print()
        print("è¿è¡Œè®­ç»ƒ:")
        print("  python train/train_delta_selfplay.py --total-timesteps 200000 --max-pool-size 20")
        print()
        print("æˆ–è€…ä½¿ç”¨ MinMax åŸºå‡†:")
        print("  python train/train_delta_selfplay.py --total-timesteps 200000 --max-pool-size 20 --use-minmax")
    else:
        print("âš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")

    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())
